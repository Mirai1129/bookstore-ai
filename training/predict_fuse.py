import datetime
import json
import os
from collections import defaultdict

import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import transforms
from PIL import Image

from training.dataset import BookDataset
from training.model_multiview import MultiViewResNet
from utils.utils import describe_condition

CSV_PATH = "../data/val_booklevel.csv"
IMG_DIR = "../data/images"
MODEL_PATH = "multiview_book_model.pt"
REPORT_PATH = "../results/book_condition_report.json"

TRANSFORM = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

def predict_single_book(model, device,
                        front_img: Image.Image | None = None,
                        spine_img: Image.Image | None = None,
                        back_img: Image.Image | None = None):
    if not any([front_img, spine_img, back_img]):
        return {"error": "è«‹è‡³å°‘ä¸Šå‚³ä¸€å¼µåœ–ç‰‡"}

    files = {"front": front_img, "spine": spine_img, "back": back_img}
    imgs_tensors = {}

    for view, img in files.items():
        if img:
            imgs_tensors[view] = TRANSFORM(img).unsqueeze(0).to(device)
        else:
            imgs_tensors[view] = torch.zeros(1, 3, 224, 224).to(device)

    model.eval()
    with torch.no_grad():
        outputs = model(imgs_tensors["front"], imgs_tensors["spine"], imgs_tensors["back"])

    pred_scores = {}
    weights = torch.arange(4, device=device, dtype=torch.float) # å‡è¨­ num_classes=4

    for attr, logits in outputs.items():
        probs = F.softmax(logits, dim=-1)
        score = torch.sum(probs * weights, dim=-1).item()
        pred_scores[attr] = float(score)

    level, desc, score = describe_condition(pred_scores)

    return {
        "level": level,
        "score": round(score, 2),
        "desc": desc
    }

def _predict_batch(model, dataloader, device, num_classes=4):
    model.eval()
    book_preds = defaultdict(dict)
    weights = torch.arange(num_classes, device=device, dtype=torch.float)

    with torch.no_grad():
        for images_tuple, labels, book_ids in dataloader:
            front_batch = images_tuple[0].to(device)
            spine_batch = images_tuple[1].to(device)
            back_batch = images_tuple[2].to(device)

            outputs = model(front_batch, spine_batch, back_batch)

            scores_by_attr = {}
            for attr in ["corner", "cover", "dirty", "damage"]:
                logits = outputs[attr]
                probs = F.softmax(logits, dim=-1)
                batch_scores = torch.sum(probs * weights, dim=-1)
                scores_by_attr[attr] = batch_scores.cpu().tolist()

            for i, book_id in enumerate(book_ids):
                book_id = str(book_id)
                final_preds = {}
                for attr in scores_by_attr:
                    final_preds[attr] = scores_by_attr[attr][i]
                book_preds[book_id] = final_preds

    return book_preds

def _load_model_for_batch(device):
    """è¼”åŠ©å‡½å¼ï¼šè¼‰å…¥æ¨¡å‹"""
    model = MultiViewResNet().to(device)
    if os.path.exists(MODEL_PATH):
        model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
        print(f"âœ… å·²è¼‰å…¥æ¨¡å‹æ¬Šé‡ {MODEL_PATH}")
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ° {MODEL_PATH}ï¼Œä½¿ç”¨éš¨æ©Ÿåˆå§‹åŒ–æ¨¡å‹")
    return model

def run_batch_prediction():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ä½¿ç”¨è¨­å‚™: {device}")

    if not os.path.exists(CSV_PATH) or not os.path.exists(IMG_DIR):
        raise FileNotFoundError("ğŸ“‚ CSV æˆ– åœ–ç‰‡è³‡æ–™å¤¾ä¸å­˜åœ¨")

    # ç¢ºä¿ BookDataset åœ¨å…§éƒ¨ä½¿ç”¨èˆ‡ API ç›¸åŒçš„ TRANSFORM
    dataset = BookDataset(CSV_PATH, IMG_DIR, transform=TRANSFORM)
    dataloader = DataLoader(dataset, batch_size=4, shuffle=False)

    model = _load_model_for_batch(device)

    print("\né–‹å§‹é æ¸¬...\n")
    preds = _predict_batch(model, dataloader, device) # å‘¼å« Batch å‡½å¼
    print(f"\nâœ… é æ¸¬å®Œæˆï¼Œå…± {len(preds)} æœ¬æ›¸\n")

    print("=" * 70)
    print("ğŸ“š äºŒæ‰‹æ›¸æ›¸æ³åˆ†æå ±å‘Š".center(70))
    print("=" * 70)

    reports = {}
    for book_id, attrs in sorted(preds.items(), key=lambda x: str(x[0])):
        level, desc, score = describe_condition(attrs)
        reports[book_id] = {
            "level": level,
            "score": round(float(score), 2),
            "desc": desc,
        }

    os.makedirs("../results", exist_ok=True)
    with open(REPORT_PATH, "w", encoding="utf-8") as f:
        json.dump(reports, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“„ å·²å°‡èåˆçµæœè¼¸å‡ºè‡³ {REPORT_PATH}")
    print("\nåˆ†æå®Œæˆï¼")
    return REPORT_PATH

def read_latest_report():
    if not os.path.exists(REPORT_PATH):
        raise FileNotFoundError(f"å ±å‘Šæª”æ¡ˆ {REPORT_PATH} ä¸å­˜åœ¨ã€‚è«‹å…ˆåŸ·è¡Œ run_batch_prediction()ã€‚")

    with open(REPORT_PATH, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data

if __name__ == "__main__":
    start_time = datetime.datetime.now()
    run_batch_prediction()
    print(f"\nTotal execution time: {datetime.datetime.now() - start_time}")