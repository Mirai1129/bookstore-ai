import json
import os
from collections import defaultdict

import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader

from training.dataset import BookDataset
from training.model_multiview import MultiViewResNet
from utils.utils import fuse_with_position_awareness, calculate_confidence, describe_condition

CSV_PATH = "data/val_booklevel.csv"
IMG_DIR = "data/raw"


def predict(model, dataloader, device, num_classes=4):
    """
    æ”¹é€²ç‰ˆé æ¸¬æµç¨‹ï¼š
    - å°‡æ¨¡å‹çš„ softmax æ©Ÿç‡è½‰ç‚ºé€£çºŒåˆ†æ•¸ (0~3)
    - ä¿ç•™ front/spine/back ä¸‰å€‹è¦–è§’çš„é æ¸¬çµæœ
    """
    model.eval()
    book_preds = defaultdict(dict)

    with torch.no_grad():
        for images_tuple, labels, book_ids in dataloader:

            view_tensors = {
                "front": images_tuple[0].to(device),
                "spine": images_tuple[1].to(device),
                "back": images_tuple[2].to(device)
            }
            # å‡è¨­ images_tuple çš„é †åºæ˜¯å›ºå®šçš„ (front, spine, back)


            weights = torch.arange(num_classes, device=device, dtype=torch.float)

            for view_name, view_tensor in view_tensors.items():
                outputs = model(view_tensor, view_tensor, view_tensor)

                scores_by_attr = {}
                for attr in ["corner", "cover", "dirty", "damage"]:
                    logits = outputs[attr]
                    probs = F.softmax(logits, dim=-1)
                    batch_scores = torch.sum(probs * weights, dim=-1)
                    scores_by_attr[attr] = batch_scores.cpu().tolist()

                for i, book_id in enumerate(book_ids):
                    book_id = str(book_id)
                    preds = {}
                    for attr in scores_by_attr:
                        preds[attr] = scores_by_attr[attr][i]

                    book_preds[book_id][view_name] = preds

    return book_preds


def _predict_data():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ä½¿ç”¨è¨­å‚™: {device}")

    if not os.path.exists(CSV_PATH):
        raise FileNotFoundError(f"ğŸ“‚ CSV æª”æ¡ˆä¸å­˜åœ¨ï¼š{CSV_PATH}")
    if not os.path.exists(IMG_DIR):
        raise FileNotFoundError(f"ğŸ“‚ åœ–ç‰‡è³‡æ–™å¤¾ä¸å­˜åœ¨ï¼š{IMG_DIR}")

    # TODO: change loading data method, we shouldn't read photo path from csv file, it should be directory.
    dataset = BookDataset(CSV_PATH, IMG_DIR)
    dataloader = DataLoader(dataset, batch_size=4, shuffle=False)

    # === è¼‰å…¥æ¨¡å‹ ===
    model = MultiViewResNet().to(device)
    if os.path.exists("multiview_book_model.pt"):
        model.load_state_dict(torch.load("multiview_book_model.pt", map_location=device))
        print("âœ… å·²è¼‰å…¥æ¨¡å‹æ¬Šé‡ multiview_book_model.pt")
    else:
        print("âš ï¸ æœªæ‰¾åˆ° multiview_book_model.ptï¼Œä½¿ç”¨éš¨æ©Ÿåˆå§‹åŒ–æ¨¡å‹ï¼ˆç¤ºç¯„ï¼‰")

    # === é æ¸¬ ===
    print("\né–‹å§‹é æ¸¬...\n")
    preds = predict(model, dataloader, device)
    print(f"\nâœ… é æ¸¬å®Œæˆï¼Œå…± {len(preds)} æœ¬æ›¸\n")

    # === èåˆèˆ‡å ±å‘Š ===
    fused = fuse_with_position_awareness(preds)

    print("=" * 70)
    print("ğŸ“š äºŒæ‰‹æ›¸æ›¸æ³åˆ†æå ±å‘Š".center(70))
    print("=" * 70)

    reports = {}

    for book_id, attrs in sorted(fused.items(), key=lambda x: str(x[0])):
        # æ”¹é€²å¾Œçš„ describe_condition
        level, desc, score = describe_condition(attrs)

        # ç½®ä¿¡åº¦è¨ˆç®—
        avg_confidence, attr_confidences = calculate_confidence(preds, book_id)

        reports[book_id] = {
            "level": level,
            "score": round(float(score), 2),
            "confidence": round(float(avg_confidence), 4),
            "desc": desc,
            "attr_confidences": {k: round(v, 4) for k, v in attr_confidences.items()}
        }

        print(f"\nğŸ“– Book ID: {book_id}")
        print(f"   æ•´é«”è©•ç´šï¼š{level}")
        print(f"   ç¶œåˆåˆ†æ•¸ï¼š{score:.2f}/3.0")
        print(f"   é æ¸¬ç½®ä¿¡åº¦ï¼š{avg_confidence:.1%}")
        print(f"   è©³ç´°ç‹€æ³ï¼š{desc}")
        print("-" * 70)

    # === å„²å­˜çµæœ ===
    os.makedirs("results", exist_ok=True)
    out_path = "results/book_condition_report.json"
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(reports, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“„ å·²å°‡èåˆçµæœè¼¸å‡ºè‡³ {out_path}")
    print("\nåˆ†æå®Œæˆï¼")
    return out_path


def get_predict_data():
    _predict_data()
    with open('results/book_condition_report.json', 'r', encoding='utf-8') as f:
        data = json.load(f)

    return data


# ==================================================
# ğŸ“– ä¸»ç¨‹å¼
# ==================================================
if __name__ == "__main__":
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ä½¿ç”¨è¨­å‚™: {device}")

    # === è¼‰å…¥è³‡æ–™ ===
    csv_path = "data/val_booklevel.csv"
    img_dir = "data/images"

    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"ğŸ“‚ CSV æª”æ¡ˆä¸å­˜åœ¨ï¼š{csv_path}")
    if not os.path.exists(img_dir):
        raise FileNotFoundError(f"ğŸ“‚ åœ–ç‰‡è³‡æ–™å¤¾ä¸å­˜åœ¨ï¼š{img_dir}")

    dataset = BookDataset(csv_path, img_dir)
    dataloader = DataLoader(dataset, batch_size=4, shuffle=False)

    # === è¼‰å…¥æ¨¡å‹ ===
    model = MultiViewResNet().to(device)
    if os.path.exists("multiview_book_model.pt"):
        model.load_state_dict(torch.load("multiview_book_model.pt", map_location=device))
        print("âœ… å·²è¼‰å…¥æ¨¡å‹æ¬Šé‡ multiview_book_model.pt")
    else:
        print("âš ï¸ æœªæ‰¾åˆ° multiview_book_model.ptï¼Œä½¿ç”¨éš¨æ©Ÿåˆå§‹åŒ–æ¨¡å‹ï¼ˆç¤ºç¯„ï¼‰")

    # === é æ¸¬ ===
    print("\né–‹å§‹é æ¸¬...\n")
    preds = predict(model, dataloader, device)
    print(f"\nâœ… é æ¸¬å®Œæˆï¼Œå…± {len(preds)} æœ¬æ›¸\n")

    # === èåˆèˆ‡å ±å‘Š ===
    fused = fuse_with_position_awareness(preds)

    print("=" * 70)
    print("ğŸ“š äºŒæ‰‹æ›¸æ›¸æ³åˆ†æå ±å‘Š".center(70))
    print("=" * 70)

    reports = {}

    for book_id, attrs in sorted(fused.items(), key=lambda x: str(x[0])):
        # æ”¹é€²å¾Œçš„ describe_condition
        level, desc, score = describe_condition(attrs)

        # ç½®ä¿¡åº¦è¨ˆç®—
        avg_confidence, attr_confidences = calculate_confidence(preds, book_id)

        reports[book_id] = {
            "level": level,
            "score": round(float(score), 2),
            "confidence": round(float(avg_confidence), 4),
            "desc": desc,
            "attr_confidences": {k: round(v, 4) for k, v in attr_confidences.items()}
        }

        print(f"\nğŸ“– Book ID: {book_id}")
        print(f"   æ•´é«”è©•ç´šï¼š{level}")
        print(f"   ç¶œåˆåˆ†æ•¸ï¼š{score:.2f}/3.0")
        print(f"   é æ¸¬ç½®ä¿¡åº¦ï¼š{avg_confidence:.1%}")
        print(f"   è©³ç´°ç‹€æ³ï¼š{desc}")
        print("-" * 70)

    # === å„²å­˜çµæœ ===
    os.makedirs("results", exist_ok=True)
    out_path = "results/book_condition_report.json"
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(reports, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“„ å·²å°‡èåˆçµæœè¼¸å‡ºè‡³ {out_path}")
    print("\nåˆ†æå®Œæˆï¼")
